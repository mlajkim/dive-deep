# Goal: Learn about the problem of current AI paradigm

Learn about XAA and Okta to realy understand the 

- Current problem we face
- How Athenz solves it with it (How Inc has such obstacles)

<!-- TOC -->

- [Goal: Learn about the problem of current AI paradigm](#goal-learn-about-the-problem-of-current-ai-paradigm)
- [Result](#result)
  - [What I learned](#what-i-learned)
  - [Next Step](#next-step)
- [Glossary](#glossary)
  - [Understand: RAG](#understand-rag)
  - [Understand: Shadow IT](#understand-shadow-it)
  - [Understand: NHI, Non-Human Identity](#understand-nhi-non-human-identity)
  - [Understand: MCP (Model Context Protocol)](#understand-mcp-model-context-protocol)
  - [Understand: A2A (Agent2Agent)](#understand-a2a-agent2agent)
- [Read and Analyze](#read-and-analyze)
  - [Understand: `The ‘superuser’ blind spot: Why AI agents demand dedicated identity security`](#understand-the-superuser-blind-spot-why-ai-agents-demand-dedicated-identity-security)
    - [Backgroud: What problems are we facing](#backgroud-what-problems-are-we-facing)
  - [Background: Legacy Protocl cannot support](#background-legacy-protocl-cannot-support)
    - [Solution: How Okta solves this problems](#solution-how-okta-solves-this-problems)

<!-- /TOC -->

# Result

It took me about 2.5 hours to read throughly.

## What I learned

- Learned some terminologies like `RAG`, `Shadow IT`, `NHI`, `MCP`, `A2A`
- Learned the problems we are facing in the AI transition and how Okta wants to solve this, in a general idea

## Next Step

I believe I can literally use this article as a first agenda of my presentation in Feb 2026.

# Glossary

## Understand: RAG

- R: `Retrieval`: Basically instead of based on the internal knowledge of its LLM, it retrieves (`searches`) relevant information from external knowledge base
- A: `Augmented`: The search result itself is then augmented as a prompt, as most of the time, user's prompt is not enough to get the nuance of the question, so the `retrived` infrormation is smartly added (`augmented`) as a part of prompt
- G: `Generation`: Generates as it is, but to make it more accurate, it makes sure that the creativity of the LLM is constrained by the retrieved information (Usually `0`, meaning it strictly follows the retrieved information)

## Understand: Shadow IT

- Light: Things that CIO/CISO understand...
- Shadow: Things that CIO/CISO don't understand...

People use non-approved softwares to get their job done, and it is very hard to track them down. It has no evil intention, but it is still a security risk, and people often used the gmail, slack, google drive, google keep etc.

Now most of the softwares above are already pre-installed, which is good but it is now AI paradigm, basically any source codes we post it to the LLM, it may be used to train the LLM, so it is a NEW security risk - or attack surface.

## Understand: NHI, Non-Human Identity


## Understand: MCP (Model Context Protocol)

Before MCP, if ChatGPT wants to read the Google Drive? We needed the API. By standalirze the protocol, AI can do the RAG easily by getting into Google Drive, etc.

- `M`: Model, basically LLM like Gemini, GPT, Claude
- `C`: Context: basically the external data that AI requires, such as db info, stock prices etc
- `P`: Protocol: Rule


## Understand: A2A (Agent2Agent) 

By specializing model, such as picture model, sound model, etc model, ai agent can ask other ai agent to do certain jobs instead of doing all by itself.

But the problem is, if agent can talk to other agent, we need to know what kind of permissions/progress it has given for that asked agent

# Read and Analyze

## Understand: `The ‘superuser’ blind spot: Why AI agents demand dedicated identity security`

![okta_identity_security](./assets/okta_identity_security.png)
https://www.okta.com/newsroom/articles/understanding-the-ai-agent-identity-challenge/


### Backgroud: What problems are we facing

It does not matter how strong your security system is if intruders have its key, and this applies for both:
- real world
- digital world

We want the AI, because it is fast/efficient for end users, but again, we need to make sure that the AI:

- does not go against the compliance
- knows what kind of access permissions that ai agent has
- can figure out what kind of permissions right away

And there is a chance that the ai agent can become the `shadow IT`, because because AI is bascially a bunch of multiple softwares grouped as one. And as a a company owner you want to make sure you know the goal, process and access permission of a comapny.

So often, however we believe that it is security vs usability, as if you give root user permission to ai agent, things get simple but your ai agent can do pretty much everything.

Also, unlie other NHI, AI agent is somewhat free. It may expose certain data with no evil intent.


## Background: Legacy Protocl cannot support

Here are the legacy protocols that we use, that are often "static":

- Static API Keys
- Oauth: Client Credentials
- Perimeter-based Security: such as VPN or IP addresses

Legacy protocols lack in:

- granulairity
- dynamic control
- centralized plane (Someone has to know whats going on in AI)

### Solution: How Okta solves this problems

To solve this problem, we need to `perimeter-based approaches` => `identity-centric model`.

This protocol wiil include:

- visibility
- permissions/controls
- governance


